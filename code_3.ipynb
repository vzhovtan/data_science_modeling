{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling exam\n",
    "# Vadim Zhovtanyuk\n",
    "# Cisco Systems, 2020\n",
    "# Code file, rel. 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics as stat\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading raw data\n",
    "file = 'training.csv'\n",
    "data = pd.read_csv(file, sep=',', header=0, parse_dates=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cust\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"segment\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vertical\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sub_vertical\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"country\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bookings\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking \"segment\" column\n",
    "data[\"segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing different names for the same country\n",
    "def fix_segment(column):\n",
    "    results = {}\n",
    "    results['column'] = column.name\n",
    "\n",
    "    #Replacing different names for the same segment\n",
    "    segment_column = []\n",
    "    for value in column:\n",
    "        if value == \"enterprise customer\":\n",
    "            segment_column.append(\"enterprise\")\n",
    "        else:\n",
    "            segment_column.append(str(value).lower())\n",
    "\n",
    "    #Creating new column data with 'fixed' entries\n",
    "    results['data'] = segment_column\n",
    "\n",
    "    return results  \n",
    "\n",
    "#Replacing data with new value\n",
    "temp_data = data.apply(fix_segment)\n",
    "for m in temp_data:\n",
    "    data[m['column']] = m['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing \"cust\" column as unique, removing \"bookings\" column which has too many unique values\n",
    "#Encoding \"segment\", \"vertical\", \"sub_vertical\" and \"purchase\" columns\n",
    "data = data.drop(\"cust\", axis=1)\n",
    "data = data.drop(\"bookings\", axis=1)\n",
    "\n",
    "encode = LabelEncoder()\n",
    "\n",
    "data[\"segment\"] = data[\"segment\"].astype(\"category\")\n",
    "data[\"segment\"] = encode.fit_transform(data.segment)\n",
    "\n",
    "data[\"vertical\"] = data[\"vertical\"].astype(\"category\")\n",
    "data[\"vertical\"] = encode.fit_transform(data.vertical)\n",
    "\n",
    "data[\"sub_vertical\"] = data[\"sub_vertical\"].astype(\"category\")\n",
    "data[\"sub_vertical\"] = encode.fit_transform(data.sub_vertical)\n",
    "\n",
    "data[\"purchase\"] = data[\"purchase\"].astype(\"category\")\n",
    "data[\"purchase\"] = encode.fit_transform(data.purchase)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking \"country\" column\n",
    "data[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing different names for the same country\n",
    "def fix(column):\n",
    "    results = {}\n",
    "    results['column'] = column.name\n",
    "\n",
    "    #Replacing different names for the same country\n",
    "    country_column = []\n",
    "    for value in column:\n",
    "        if value == \"usa\":\n",
    "            country_column.append(\"united states\")\n",
    "        elif value == \"deutschland\":\n",
    "            country_column.append(\"germany\")\n",
    "        else:\n",
    "            country_column.append(value)\n",
    "\n",
    "    #Creating new column data with 'fixed' entries\n",
    "    results['data'] = country_column\n",
    "\n",
    "    return results  \n",
    "\n",
    "#Replacing data with new value\n",
    "temp_data = data.apply(fix)\n",
    "for m in temp_data:\n",
    "    data[m['column']] = m['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding \"country\" column \n",
    "data[\"country\"] = data[\"country\"].astype(\"category\")\n",
    "data[\"country\"] = encode.fit_transform(data.country)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling all cloumns\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data['vert_scaled'] = scaler.fit_transform(data['vertical'].values.reshape(-1,1))\n",
    "data = data.drop(\"vertical\", axis=1)\n",
    "data['sub_scaled'] = scaler.fit_transform(data['sub_vertical'].values.reshape(-1,1))\n",
    "data = data.drop(\"sub_vertical\", axis=1)\n",
    "data['country_scaled'] = scaler.fit_transform(data['country'].values.reshape(-1,1))\n",
    "data = data.drop(\"country\", axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['country_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data[\"country_scaled\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vert_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data[\"vert_scaled\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sub_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data[\"sub_scaled\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "plotting_data = data.drop(\"purchase\", axis=1)\n",
    "plotting_data.hist(figsize=(12,12)) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data.plot.kde(figsize=(20,10),subplots=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data.plot.box(vert=False, figsize=(12,8))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import radviz\n",
    "pyplot.figure(figsize=(30,16))\n",
    "radviz(data, 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create feature and target for classification\n",
    "features_1 = data.drop(\"purchase\", axis=1).values\n",
    "target_1 = data[\"purchase\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data for training and testing sets\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(features_1, target_1, test_size = 0.3, random_state = 42, stratify = target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train has: segment, vert_scaled, sub_scaled, country_scaled\n",
    "X_train_1[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2\n",
    "test = SelectKBest(score_func=chi2, k=3) \n",
    "fit = test.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fit.transform(X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate selected 3 best features - vert_scaled, sub_scaled, country_scaled\n",
    "features[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to use RFE\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression() \n",
    "rfe = RFE(model, 3) \n",
    "fit = rfe.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE selected the same 3 best features - vert_scaled, sub_scaled, country_scaled\n",
    "fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to use PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3) \n",
    "fit = pca.fit(X_train_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier() \n",
    "model.fit(X_train_1, y_train_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All feature selection approaches returned the same features to be used for future analysis - vert_scaled, sub_scaled, country_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new feature and target for classification after feature selection done by removing segment. Target is still the same.\n",
    "target_2 = data[\"purchase\"].values\n",
    "data_2 = data.drop(\"segment\", axis=1)\n",
    "features_2 = data_2.drop(\"purchase\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the new data for training and testing sets\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(features_2, target_2, test_size = 0.3, random_state = 42, stratify = target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data_2 = data_2.drop(\"purchase\", axis=1)\n",
    "plotting_data_2.plot.kde(figsize=(20,10),subplots=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new feature and target for classification after feature selection done by removing country for the testing. Target is still the same.\n",
    "target_3 = data[\"purchase\"].values\n",
    "data_3 = data_2.drop(\"country_scaled\", axis=1)\n",
    "features_3 = data_2.drop(\"purchase\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the new data for training and testing sets\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(features_3, target_3, test_size = 0.3, random_state = 42, stratify = target_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data_3 = data_3.drop(\"purchase\", axis=1)\n",
    "plotting_data_3.plot.kde(figsize=(12,8),subplots=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data_3.plot.box(vert=False, figsize=(12,8))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare models \n",
    "models = [] \n",
    "models.append((\"LR\", LogisticRegression())) \n",
    "models.append((\"LDA\", LinearDiscriminantAnalysis())) \n",
    "models.append((\"KNN\", KNeighborsClassifier())) \n",
    "models.append((\"CART\", DecisionTreeClassifier())) \n",
    "models.append((\"NB\", GaussianNB())) \n",
    "models.append((\"SVM\", SVC())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate each model in turn for feature set 1\n",
    "results_1 = [] \n",
    "names_1 = [] \n",
    "scoring = \"accuracy\" \n",
    "for name, model in models: \n",
    "   kfold = KFold(n_splits=10, random_state=7, shuffle=True) \n",
    "   cv_results = cross_val_score(model, X_train_1, y_train_1, cv=kfold, scoring=scoring)\n",
    "   results_1.append(cv_results)\n",
    "   names_1.append(name) \n",
    "   msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "   print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot algorithm comparison for feature set 1\n",
    "fig = pyplot.figure(figsize=(12,8)) \n",
    "fig.suptitle(\"Algorithm Comparison\") \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results_1) \n",
    "ax.set_xticklabels(names_1) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate each model in turn for feature set 2\n",
    "results_2 = [] \n",
    "names_2 = [] \n",
    "scoring = \"accuracy\" \n",
    "for name, model in models: \n",
    "   kfold = KFold(n_splits=10, random_state=7, shuffle=True) \n",
    "   cv_results = cross_val_score(model, X_train_2, y_train_2, cv=kfold, scoring=scoring)\n",
    "   results_2.append(cv_results)\n",
    "   names_2.append(name) \n",
    "   msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "   print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot algorithm comparison for feature set 2\n",
    "fig = pyplot.figure(figsize=(12,8)) \n",
    "fig.suptitle(\"Algorithm Comparison\") \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results_2) \n",
    "ax.set_xticklabels(names_2) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate each model in turn for feature set 3\n",
    "results_3 = [] \n",
    "names_3 = [] \n",
    "scoring = \"accuracy\" \n",
    "for name, model in models: \n",
    "   kfold = KFold(n_splits=10, random_state=7, shuffle=True) \n",
    "   cv_results = cross_val_score(model, X_train_3, y_train_3, cv=kfold, scoring=scoring)\n",
    "   results_3.append(cv_results)\n",
    "   names_3.append(name) \n",
    "   msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "   print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot algorithm comparison for feature set 3\n",
    "fig = pyplot.figure(figsize=(12,8)) \n",
    "fig.suptitle(\"Algorithm Comparison\") \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results_3) \n",
    "ax.set_xticklabels(names_3) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating 6 different algorithms shows LR, LDA, NB and SVM give the same score for all feature sets\n",
    "#Selecting LDA to use pipeline for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline \n",
    "estimators = [] \n",
    "estimators.append((\"standardize\", StandardScaler())) \n",
    "estimators.append((\"lda\", LinearDiscriminantAnalysis())) \n",
    "model = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate pipeline for feature set 1\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True) \n",
    "results = cross_val_score(model, X_train_1, y_train_1, cv=kfold) \n",
    "print(results.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
